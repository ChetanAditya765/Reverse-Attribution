{
  "imdb_results": {
    "accuracy": 0.93584,
    "ece": 0.04800824696540834,
    "brier_score": 0.05513133769792232,
    "avg_a_flip": 137.7222330883657,
    "std_a_flip": 46.61936881846788,
    "avg_counter_evidence_count": 5.0,
    "avg_counter_evidence_strength": 0.06612640894920332,
    "samples_analyzed": 200,
    "error_samples": 0,
    "pct_samples_with_counter_evidence": 0.0,
    "model_type": "BERTSentimentClassifier",
    "model_class": "unknown"
  },
  "yelp_results": {
    "accuracy": 0.9798684210526316,
    "ece": 0.009824317456860255,
    "brier_score": 0.01625467042265758,
    "avg_a_flip": 26.067429713831057,
    "std_a_flip": 11.212644833957444,
    "avg_counter_evidence_count": 5.0,
    "avg_counter_evidence_strength": 0.0,
    "samples_analyzed": 200,
    "error_samples": 0,
    "pct_samples_with_counter_evidence": 0.0,
    "model_type": "BERTSentimentClassifier",
    "model_class": "unknown"
  },
  "cifar10_results": {
    "accuracy": 0.9328,
    "ece": 0.045081186604499834,
    "brier_score": 0.011184436759987457,
    "avg_a_flip": 819.411162386543,
    "std_a_flip": 300.33467076582696,
    "avg_counter_evidence_count": 5.0,
    "avg_counter_evidence_strength": 0.0,
    "samples_analyzed": 200,
    "error_samples": 0,
    "pct_samples_with_counter_evidence": 0.0,
    "model_type": "ResNetCIFAR",
    "model_class": "unknown"
  }
}